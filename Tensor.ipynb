{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 01:05:36.727259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 01:05:37.314311: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-09 01:05:39.631901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 01:05:39.632111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 01:05:39.632124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling2D, TimeDistributed, Conv1D, Conv2D, GlobalAveragePooling1D, MaxPool2D, Flatten, add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# silence tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# getting rid of the warning messages about optimizer graph\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "Tensorflow version: 2.11.0\n",
      "Keras version: 2.11.0\n",
      "Using NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 01:05:43.580697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:43.991384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:43.991443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:44.003777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:44.003996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:44.004061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.336830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.337918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.337951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 01:05:48.338038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.339031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-05-09 01:05:48.344913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# print Tensorflow and CUDA information\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    " \n",
    "if tf.test.gpu_device_name():\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "    name = details.get('device_name', 'Unknown GPU')\n",
    "    \n",
    "    print(f\"Using {name}\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 01:05:48.434471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.435812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.435901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.436445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.436471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 01:05:48.436547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 01:05:48.436595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import vggish_params as params\n",
    "\n",
    "\n",
    "path = 'vggish_model.ckpt'\n",
    "\n",
    "class VGGish(tf.keras.Model):\n",
    "    def __init__(self, training=False):\n",
    "        super(VGGish, self).__init__()\n",
    "        self.training = training\n",
    "\n",
    "        # The VGG stack of alternating convolutions and max-pools.\n",
    "        self.conv1 = Conv2D(64, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool1 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv2 = Conv2D(128, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool2 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv3_1 = Conv2D(256, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.conv3_2 = Conv2D(256, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool3 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv4_1 = Conv2D(512, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.conv4_2 = Conv2D(512, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool4 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "\n",
    "        # Flatten before entering fully-connected layers\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1_1 = Dense(4096, activation=tf.nn.relu, trainable=self.training)\n",
    "        self.fc1_2 = Dense(4096, activation=tf.nn.relu, trainable=self.training)\n",
    "        # The embedding layer.\n",
    "        self.fc2 = Dense(params.EMBEDDING_SIZE, activation=None, trainable=self.training)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3_1(net)\n",
    "        net = self.conv3_2(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.conv4_1(net)\n",
    "        net = self.conv4_2(net)\n",
    "        net = self.pool4(net)\n",
    "\n",
    "        net = self.flatten(net)\n",
    "        net = self.fc1_1(net)\n",
    "        net = self.fc1_2(net)\n",
    "        net = self.fc2(net)\n",
    "        \n",
    "        return net\n",
    "\n",
    "    def load_vggish_slim_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Loads a pre-trained VGGish-compatible checkpoint.\"\"\"\n",
    "        self.load_weights(checkpoint_path)\n",
    "\n",
    "vggish = VGGish()\n",
    "vggish.load_vggish_slim_checkpoint(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vg_gish_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vg_gish (VGGish)            multiple                  72141184  \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  66048     \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  65664     \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  2580      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,439,700\n",
      "Trainable params: 298,516\n",
      "Non-trainable params: 72,141,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import vggish_input\n",
    "\n",
    "class VGGishClassifier(tf.keras.Model):\n",
    "    def __init__(self, vggish_model, num_classes):\n",
    "        super(VGGishClassifier, self).__init__()\n",
    "        self.vggish_model = vggish_model\n",
    "        self.dense1 = Dense(512, activation='relu')\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dense3 = Dense(128, activation='relu')\n",
    "        self.skip1 = Dense(128, activation='relu')\n",
    "        self.dense4 = Dense(num_classes, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.vggish_model(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = self.skip1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = add([x, skip])\n",
    "        x = self.dense4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 20  # Set the number of classes as needed\n",
    "classifier_model = VGGishClassifier(vggish, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                         loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "# Prepare the input data and labels\n",
    "batch_size = 10\n",
    "num_frames = params.NUM_FRAMES\n",
    "num_bands = params.NUM_BANDS\n",
    "\n",
    "input_data = np.random.rand(batch_size, num_frames, num_bands, 1).astype(np.float32)\n",
    "# labels = np.random.randint(0, num_classes, size=(batch_size,))\n",
    "# force all labels to be the same\n",
    "labels = np.ones((batch_size,)) * 5\n",
    "\n",
    "classifier_model.build(input_shape=(None, params.NUM_FRAMES, params.NUM_BANDS, 1))\n",
    "classifier_model.summary()\n",
    "\n",
    "# Train the classifier model\n",
    "if False:\n",
    "    classifier_model.fit(input_data, labels, epochs=10)\n",
    "\n",
    "    predictions = classifier_model.predict(input_data)\n",
    "\n",
    "    print(f\"Predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000135_483840' '000139_119040' '000141_153600' '000144_30720'\n",
      " '000145_172800']\n",
      "['000308_61440' '000312_184320' '000319_145920' '000321_218880'\n",
      " '000327_88320']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# train csv path\n",
    "train_csv_path = 'openmic-2018/partitions/split01_train.csv'\n",
    "# test csv path\n",
    "test_csv_path = 'openmic-2018/partitions/split01_test.csv'\n",
    "\n",
    "# open csvs\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# convert to numpy arrays\n",
    "train_df = train_df.to_numpy()\n",
    "test_df = test_df.to_numpy()\n",
    "\n",
    "# make each a single list\n",
    "train_df = train_df.flatten()\n",
    "test_df = test_df.flatten()\n",
    "\n",
    "# print the first 5 rows of the train and test dataframes\n",
    "print(train_df[:5])\n",
    "print(test_df[:5])\n",
    "\n",
    "# only use the first 10% of each csv\n",
    "train_df = train_df[:int(len(train_df) * 0.01)]\n",
    "test_df = test_df[:int(len(test_df) * 0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (149, 10, 96, 64)\n",
      "Labels shape: (149, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'spectrograms'\n",
    "labels_path = 'labels.csv'\n",
    "\n",
    "# Read the labels CSV file\n",
    "# ['filename' 'clarinet' 'flute' 'trumpet' 'saxophone' 'voice' 'accordion' 'ukulele' 'mallet_percussion' 'piano' 'guitar' 'mandolin' 'banjo' 'synthesizer' 'trombone' 'organ' 'drums' 'bass' 'cymbals' 'cello' 'violin']\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "# Get the list of all the filenames\n",
    "filenames = labels_df['filename'].values.tolist()\n",
    "\n",
    "# load the spectrograms and labels\n",
    "spectrograms_train = []\n",
    "labels_train = []\n",
    "\n",
    "spectrograms_test = []\n",
    "labels_test = []\n",
    "\n",
    "for filename in filenames:\n",
    "    # if the filename is not in the train or test dataframe, skip it\n",
    "    if filename not in train_df and filename not in test_df:\n",
    "        continue\n",
    "\n",
    "    # load the spectrogram\n",
    "    spectrogram = np.load(os.path.join(dataset_path, filename + '.npy'))\n",
    "\n",
    "    # get the label\n",
    "    label = labels_df[labels_df['filename'] == filename].values.tolist()[0][1:]\n",
    "    '''\n",
    "    # append each second seperatly\n",
    "    if filename in train_df:\n",
    "        for i in range(10):\n",
    "            spectrograms_train.append(spectrogram[i])\n",
    "            labels_train.append(label)\n",
    "    elif filename in test_df:\n",
    "        for i in range(10):\n",
    "            spectrograms_test.append(spectrogram[i])\n",
    "            labels_test.append(label)\n",
    "    else:\n",
    "        continue\n",
    "        # print(f\"Filename {filename} not found in train or test dataframes\")\n",
    "    '''\n",
    "    # append the spectrogram and label\n",
    "    if filename in train_df:\n",
    "        spectrograms_train.append(spectrogram)\n",
    "        labels_train.append(label)\n",
    "    elif filename in test_df:\n",
    "        spectrograms_test.append(spectrogram)\n",
    "        labels_test.append(label)\n",
    "    else:\n",
    "        continue\n",
    "        # print(f\"Filename {filename} not found in train or test dataframes\")\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "spectrograms_train = np.array(spectrograms_train)\n",
    "labels_train = np.array(labels_train)\n",
    "\n",
    "spectrograms_test = np.array(spectrograms_test)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "#spectrograms = spectrograms.reshape(spectrograms.shape[0], num_frames, num_bands, 1)\n",
    "spectrograms_test = np.expand_dims(spectrograms_test, axis=-1)\n",
    "spectrograms_train = np.expand_dims(spectrograms_train, axis=-1)\n",
    "\n",
    "\n",
    "print(f\"Spectrograms shape: {spectrograms_train.shape}\")\n",
    "print(f\"Labels shape: {labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1490, 96, 64, 1)\n",
      "y_train shape: (1490, 20)\n",
      "X_test shape: (500, 96, 64, 1)\n",
      "y_test shape: (500, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(spectrograms, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = spectrograms_train\n",
    "y_train = labels_train\n",
    "\n",
    "X_test = spectrograms_test\n",
    "y_test = labels_test\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vg_gish_classifier_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vg_gish (VGGish)            multiple                  72141184  \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  66048     \n",
      "                                                                 \n",
      " dense_24 (Dense)            multiple                  131328    \n",
      "                                                                 \n",
      " dense_25 (Dense)            multiple                  32896     \n",
      "                                                                 \n",
      " dense_26 (Dense)            multiple                  65664     \n",
      "                                                                 \n",
      " dense_27 (Dense)            multiple                  2580      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,439,700\n",
      "Trainable params: 298,516\n",
      "Non-trainable params: 72,141,184\n",
      "_________________________________________________________________\n",
      "Epoch 1/64\n",
      "6/6 [==============================] - 29s 6s/step - loss: 0.6611 - accuracy: 0.0725 - f1: 0.0923 - val_loss: 0.5937 - val_accuracy: 0.1600 - val_f1: 0.0152\n",
      "Epoch 2/64\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.5304 - accuracy: 0.0872 - f1: 0.0407 - val_loss: 0.3868 - val_accuracy: 0.1000 - val_f1: 0.0000e+00\n",
      "Epoch 3/64\n",
      "6/6 [==============================] - 1s 247ms/step - loss: 0.3846 - accuracy: 0.1020 - f1: 0.0153 - val_loss: 0.3160 - val_accuracy: 0.1000 - val_f1: 0.0000e+00\n",
      "Epoch 4/64\n",
      "6/6 [==============================] - 1s 248ms/step - loss: 0.3703 - accuracy: 0.0987 - f1: 0.0024 - val_loss: 0.3166 - val_accuracy: 0.1000 - val_f1: 0.0000e+00\n",
      "Epoch 5/64\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.3472 - accuracy: 0.0785 - f1: 0.0022 - val_loss: 0.3153 - val_accuracy: 0.0400 - val_f1: 0.0000e+00\n",
      "Epoch 6/64\n",
      "6/6 [==============================] - 1s 226ms/step - loss: 0.3439 - accuracy: 0.0752 - f1: 0.0037 - val_loss: 0.3186 - val_accuracy: 0.0400 - val_f1: 0.0000e+00\n",
      "Epoch 7/64\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.3376 - accuracy: 0.0799 - f1: 2.7778e-04 - val_loss: 0.3093 - val_accuracy: 0.1280 - val_f1: 0.0000e+00\n",
      "Epoch 8/64\n",
      "6/6 [==============================] - 1s 226ms/step - loss: 0.3333 - accuracy: 0.1034 - f1: 3.0864e-04 - val_loss: 0.3078 - val_accuracy: 0.1000 - val_f1: 0.0000e+00\n",
      "Epoch 9/64\n",
      "6/6 [==============================] - 1s 249ms/step - loss: 0.3316 - accuracy: 0.1141 - f1: 0.0000e+00 - val_loss: 0.3075 - val_accuracy: 0.0920 - val_f1: 0.0000e+00\n",
      "Epoch 10/64\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.3280 - accuracy: 0.0906 - f1: 0.0000e+00 - val_loss: 0.3091 - val_accuracy: 0.0860 - val_f1: 0.0000e+00\n",
      "Epoch 11/64\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.3253 - accuracy: 0.1047 - f1: 0.0000e+00 - val_loss: 0.3084 - val_accuracy: 0.0400 - val_f1: 0.0000e+00\n",
      "Epoch 12/64\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.3251 - accuracy: 0.1020 - f1: 0.0000e+00 - val_loss: 0.3073 - val_accuracy: 0.0400 - val_f1: 0.0000e+00\n",
      "Epoch 13/64\n",
      "6/6 [==============================] - 1s 252ms/step - loss: 0.3244 - accuracy: 0.0919 - f1: 0.0000e+00 - val_loss: 0.3071 - val_accuracy: 0.0540 - val_f1: 0.0000e+00\n",
      "Epoch 14/64\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.3226 - accuracy: 0.1128 - f1: 0.0000e+00 - val_loss: 0.3080 - val_accuracy: 0.1320 - val_f1: 0.0000e+00\n",
      "Epoch 15/64\n",
      "6/6 [==============================] - 1s 261ms/step - loss: 0.3222 - accuracy: 0.1248 - f1: 0.0000e+00 - val_loss: 0.3074 - val_accuracy: 0.1360 - val_f1: 0.0000e+00\n",
      "Epoch 16/64\n",
      "6/6 [==============================] - 1s 259ms/step - loss: 0.3211 - accuracy: 0.1094 - f1: 0.0000e+00 - val_loss: 0.3070 - val_accuracy: 0.0960 - val_f1: 0.0000e+00\n",
      "Epoch 17/64\n",
      "6/6 [==============================] - 1s 257ms/step - loss: 0.3205 - accuracy: 0.1087 - f1: 0.0000e+00 - val_loss: 0.3071 - val_accuracy: 0.0600 - val_f1: 0.0000e+00\n",
      "Epoch 18/64\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.3202 - accuracy: 0.0919 - f1: 0.0000e+00 - val_loss: 0.3079 - val_accuracy: 0.0780 - val_f1: 0.0000e+00\n",
      "Epoch 19/64\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.3190 - accuracy: 0.1188 - f1: 0.0000e+00 - val_loss: 0.3066 - val_accuracy: 0.1120 - val_f1: 0.0000e+00\n",
      "Epoch 20/64\n",
      "6/6 [==============================] - 1s 257ms/step - loss: 0.3185 - accuracy: 0.1134 - f1: 0.0000e+00 - val_loss: 0.3058 - val_accuracy: 0.1140 - val_f1: 0.0000e+00\n",
      "Epoch 21/64\n",
      "6/6 [==============================] - 1s 259ms/step - loss: 0.3182 - accuracy: 0.1034 - f1: 0.0000e+00 - val_loss: 0.3062 - val_accuracy: 0.0880 - val_f1: 0.0000e+00\n",
      "Epoch 22/64\n",
      "6/6 [==============================] - 1s 257ms/step - loss: 0.3173 - accuracy: 0.1040 - f1: 0.0000e+00 - val_loss: 0.3057 - val_accuracy: 0.0940 - val_f1: 0.0000e+00\n",
      "Epoch 23/64\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.3164 - accuracy: 0.1141 - f1: 0.0000e+00 - val_loss: 0.3050 - val_accuracy: 0.1040 - val_f1: 0.0000e+00\n",
      "Epoch 24/64\n",
      "6/6 [==============================] - 1s 261ms/step - loss: 0.3158 - accuracy: 0.1161 - f1: 0.0000e+00 - val_loss: 0.3053 - val_accuracy: 0.1080 - val_f1: 0.0000e+00\n",
      "Epoch 25/64\n",
      "6/6 [==============================] - 1s 254ms/step - loss: 0.3149 - accuracy: 0.0987 - f1: 0.0000e+00 - val_loss: 0.3057 - val_accuracy: 0.0960 - val_f1: 0.0000e+00\n",
      "Epoch 26/64\n",
      "6/6 [==============================] - 1s 261ms/step - loss: 0.3142 - accuracy: 0.1060 - f1: 0.0000e+00 - val_loss: 0.3040 - val_accuracy: 0.1020 - val_f1: 0.0000e+00\n",
      "Epoch 27/64\n",
      "6/6 [==============================] - 1s 261ms/step - loss: 0.3138 - accuracy: 0.1181 - f1: 0.0000e+00 - val_loss: 0.3030 - val_accuracy: 0.1040 - val_f1: 0.0000e+00\n",
      "Epoch 28/64\n",
      "6/6 [==============================] - 1s 259ms/step - loss: 0.3126 - accuracy: 0.1161 - f1: 0.0000e+00 - val_loss: 0.3026 - val_accuracy: 0.1020 - val_f1: 0.0000e+00\n",
      "Epoch 29/64\n",
      "6/6 [==============================] - 1s 232ms/step - loss: 0.3120 - accuracy: 0.1188 - f1: 7.7128e-04 - val_loss: 0.3031 - val_accuracy: 0.1020 - val_f1: 0.0000e+00\n",
      "Epoch 30/64\n",
      "6/6 [==============================] - 1s 266ms/step - loss: 0.3111 - accuracy: 0.1148 - f1: 0.0015 - val_loss: 0.3025 - val_accuracy: 0.1020 - val_f1: 0.0000e+00\n",
      "Epoch 31/64\n",
      "6/6 [==============================] - 1s 263ms/step - loss: 0.3102 - accuracy: 0.1081 - f1: 0.0046 - val_loss: 0.3016 - val_accuracy: 0.1180 - val_f1: 0.0000e+00\n",
      "Epoch 32/64\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.3106 - accuracy: 0.1060 - f1: 0.0051 - val_loss: 0.3016 - val_accuracy: 0.1180 - val_f1: 0.0000e+00\n",
      "Epoch 33/64\n",
      "6/6 [==============================] - 1s 235ms/step - loss: 0.3086 - accuracy: 0.1067 - f1: 0.0116 - val_loss: 0.3007 - val_accuracy: 0.1300 - val_f1: 0.0000e+00\n",
      "Epoch 34/64\n",
      "6/6 [==============================] - 1s 259ms/step - loss: 0.3078 - accuracy: 0.1148 - f1: 0.0130 - val_loss: 0.3006 - val_accuracy: 0.1340 - val_f1: 0.0143\n",
      "Epoch 35/64\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.3074 - accuracy: 0.1161 - f1: 0.0155 - val_loss: 0.3004 - val_accuracy: 0.1320 - val_f1: 0.0155\n",
      "Epoch 36/64\n",
      "6/6 [==============================] - 1s 266ms/step - loss: 0.3066 - accuracy: 0.1195 - f1: 0.0197 - val_loss: 0.3001 - val_accuracy: 0.1280 - val_f1: 0.0155\n",
      "Epoch 37/64\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.3067 - accuracy: 0.1181 - f1: 0.0194 - val_loss: 0.2991 - val_accuracy: 0.1260 - val_f1: 0.0155\n",
      "Epoch 38/64\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.3062 - accuracy: 0.1255 - f1: 0.0204 - val_loss: 0.3000 - val_accuracy: 0.1260 - val_f1: 0.0177\n",
      "Epoch 39/64\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.3053 - accuracy: 0.1101 - f1: 0.0240 - val_loss: 0.2999 - val_accuracy: 0.1280 - val_f1: 0.0155\n",
      "Epoch 40/64\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.3052 - accuracy: 0.1114 - f1: 0.0220 - val_loss: 0.2994 - val_accuracy: 0.1240 - val_f1: 0.0155\n",
      "Epoch 41/64\n",
      "6/6 [==============================] - 1s 261ms/step - loss: 0.3047 - accuracy: 0.1228 - f1: 0.0226 - val_loss: 0.2991 - val_accuracy: 0.1240 - val_f1: 0.0177\n",
      "Epoch 42/64\n",
      "6/6 [==============================] - 1s 265ms/step - loss: 0.3037 - accuracy: 0.1235 - f1: 0.0230 - val_loss: 0.2992 - val_accuracy: 0.1280 - val_f1: 0.0187\n",
      "Epoch 43/64\n",
      "6/6 [==============================] - 1s 259ms/step - loss: 0.3042 - accuracy: 0.1248 - f1: 0.0239 - val_loss: 0.2990 - val_accuracy: 0.1300 - val_f1: 0.0177\n",
      "Epoch 44/64\n",
      "6/6 [==============================] - 1s 261ms/step - loss: 0.3040 - accuracy: 0.1262 - f1: 0.0243 - val_loss: 0.2986 - val_accuracy: 0.1260 - val_f1: 0.0167\n",
      "Epoch 45/64\n",
      "6/6 [==============================] - 1s 262ms/step - loss: 0.3035 - accuracy: 0.1309 - f1: 0.0230 - val_loss: 0.2988 - val_accuracy: 0.1280 - val_f1: 0.0177\n",
      "Epoch 46/64\n",
      "6/6 [==============================] - 2s 268ms/step - loss: 0.3026 - accuracy: 0.1195 - f1: 0.0254 - val_loss: 0.2987 - val_accuracy: 0.1260 - val_f1: 0.0187\n",
      "Epoch 47/64\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.3030 - accuracy: 0.1228 - f1: 0.0232 - val_loss: 0.2984 - val_accuracy: 0.1240 - val_f1: 0.0177\n",
      "Epoch 48/64\n",
      "6/6 [==============================] - 1s 263ms/step - loss: 0.3025 - accuracy: 0.1255 - f1: 0.0216 - val_loss: 0.2982 - val_accuracy: 0.1180 - val_f1: 0.0187\n",
      "Epoch 49/64\n",
      "6/6 [==============================] - 1s 259ms/step - loss: 0.3023 - accuracy: 0.1255 - f1: 0.0238 - val_loss: 0.2985 - val_accuracy: 0.1280 - val_f1: 0.0177\n",
      "Epoch 50/64\n",
      "6/6 [==============================] - 1s 233ms/step - loss: 0.3017 - accuracy: 0.1228 - f1: 0.0240 - val_loss: 0.2983 - val_accuracy: 0.1200 - val_f1: 0.0187\n",
      "Epoch 51/64\n",
      "6/6 [==============================] - 1s 262ms/step - loss: 0.3019 - accuracy: 0.1282 - f1: 0.0238 - val_loss: 0.2979 - val_accuracy: 0.1280 - val_f1: 0.0167\n",
      "Epoch 52/64\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.3014 - accuracy: 0.1215 - f1: 0.0233 - val_loss: 0.2976 - val_accuracy: 0.1240 - val_f1: 0.0187\n",
      "Epoch 53/64\n",
      "6/6 [==============================] - 1s 255ms/step - loss: 0.3005 - accuracy: 0.1282 - f1: 0.0251 - val_loss: 0.2980 - val_accuracy: 0.1280 - val_f1: 0.0187\n",
      "Epoch 54/64\n",
      "6/6 [==============================] - 1s 260ms/step - loss: 0.3005 - accuracy: 0.1242 - f1: 0.0241 - val_loss: 0.2983 - val_accuracy: 0.1300 - val_f1: 0.0187\n",
      "Epoch 55/64\n",
      "6/6 [==============================] - 1s 258ms/step - loss: 0.3003 - accuracy: 0.1201 - f1: 0.0250 - val_loss: 0.2978 - val_accuracy: 0.1400 - val_f1: 0.0187\n",
      "Epoch 56/64\n",
      "6/6 [==============================] - 1s 257ms/step - loss: 0.3005 - accuracy: 0.1315 - f1: 0.0244 - val_loss: 0.2987 - val_accuracy: 0.1240 - val_f1: 0.0187\n",
      "Epoch 57/64\n",
      "6/6 [==============================] - 1s 262ms/step - loss: 0.3001 - accuracy: 0.1262 - f1: 0.0258 - val_loss: 0.2967 - val_accuracy: 0.1340 - val_f1: 0.0187\n",
      "Epoch 58/64\n",
      "6/6 [==============================] - 1s 264ms/step - loss: 0.2993 - accuracy: 0.1228 - f1: 0.0251 - val_loss: 0.2971 - val_accuracy: 0.1360 - val_f1: 0.0167\n",
      "Epoch 59/64\n",
      "6/6 [==============================] - 1s 261ms/step - loss: 0.2987 - accuracy: 0.1221 - f1: 0.0252 - val_loss: 0.2979 - val_accuracy: 0.1300 - val_f1: 0.0187\n",
      "Epoch 60/64\n",
      "6/6 [==============================] - 2s 268ms/step - loss: 0.2990 - accuracy: 0.1295 - f1: 0.0265 - val_loss: 0.2978 - val_accuracy: 0.1320 - val_f1: 0.0187\n",
      "Epoch 61/64\n",
      "6/6 [==============================] - 1s 262ms/step - loss: 0.2988 - accuracy: 0.1315 - f1: 0.0250 - val_loss: 0.2978 - val_accuracy: 0.1300 - val_f1: 0.0187\n",
      "Epoch 62/64\n",
      "6/6 [==============================] - 1s 266ms/step - loss: 0.2985 - accuracy: 0.1235 - f1: 0.0246 - val_loss: 0.2966 - val_accuracy: 0.1360 - val_f1: 0.0187\n",
      "Epoch 63/64\n",
      "6/6 [==============================] - 1s 264ms/step - loss: 0.2981 - accuracy: 0.1302 - f1: 0.0238 - val_loss: 0.2979 - val_accuracy: 0.1300 - val_f1: 0.0187\n",
      "Epoch 64/64\n",
      "6/6 [==============================] - 2s 268ms/step - loss: 0.2974 - accuracy: 0.1289 - f1: 0.0259 - val_loss: 0.2975 - val_accuracy: 0.1320 - val_f1: 0.0187\n",
      "16/16 [==============================] - 2s 144ms/step\n",
      "Predictions shape: (500, 20)\n",
      "First prediction: [0.12 0.09 0.17 0.14 0.05 0.08 0.14 0.1  0.07 0.02 0.13 0.11 0.09 0.15\n",
      " 0.09 0.06 0.08 0.06 0.07 0.11]\n",
      "First label:      [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# import f1\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "@tf.function\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Computes the F1 score.\n",
    "\n",
    "    Computes the F1 score between the labels and predictions.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=0)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=0)\n",
    "\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return K.mean(f1_val)\n",
    "\n",
    "num_classes = 20  # Set the number of classes as needed\n",
    "classifier_model = VGGishClassifier(vggish, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                         loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                         metrics=['accuracy', f1])\n",
    "\n",
    "classifier_model.build(input_shape=(None, params.NUM_FRAMES, params.NUM_BANDS, 1))\n",
    "\n",
    "classifier_model.summary()\n",
    "\n",
    "\n",
    "classifier_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=64, batch_size=256)\n",
    "\n",
    "predictions = classifier_model.predict(X_test)\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "\n",
    "# print the first prediction rounded to 2 decimal places\n",
    "print(f\"First prediction: {np.round(predictions[5], 2)}\")\n",
    "print(f\"First label:      {y_test[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
