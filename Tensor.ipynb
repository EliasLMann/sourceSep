{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 02:20:39.054961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 02:20:39.317007: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-09 02:20:39.974221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 02:20:39.974331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 02:20:39.974336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling2D, TimeDistributed, Conv1D, Conv2D, GlobalAveragePooling1D, MaxPool2D, Flatten, add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# silence tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# getting rid of the warning messages about optimizer graph\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "Tensorflow version: 2.11.0\n",
      "Keras version: 2.11.0\n",
      "Using NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 02:20:41.303688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:41.469730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:41.469770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:41.488651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:41.488726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:41.488742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.660164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.660325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.660334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 02:20:42.660356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.660441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-05-09 02:20:42.664916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# print Tensorflow and CUDA information\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    " \n",
    "if tf.test.gpu_device_name():\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "    name = details.get('device_name', 'Unknown GPU')\n",
    "    \n",
    "    print(f\"Using {name}\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 02:20:42.744169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.744285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.744304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.744641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.744654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 02:20:42.744677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 02:20:42.744693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import vggish_params as params\n",
    "\n",
    "\n",
    "path = 'vggish_model.ckpt'\n",
    "\n",
    "class VGGish(tf.keras.Model):\n",
    "    def __init__(self, training=False):\n",
    "        super(VGGish, self).__init__()\n",
    "        self.training = training\n",
    "\n",
    "        # The VGG stack of alternating convolutions and max-pools.\n",
    "        self.conv1 = Conv2D(64, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool1 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv2 = Conv2D(128, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool2 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv3_1 = Conv2D(256, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.conv3_2 = Conv2D(256, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool3 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv4_1 = Conv2D(512, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.conv4_2 = Conv2D(512, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool4 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "\n",
    "        # Flatten before entering fully-connected layers\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1_1 = Dense(4096, activation=tf.nn.relu, trainable=self.training)\n",
    "        self.fc1_2 = Dense(4096, activation=tf.nn.relu, trainable=self.training)\n",
    "        # The embedding layer.\n",
    "        self.fc2 = Dense(params.EMBEDDING_SIZE, activation=None, trainable=self.training)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3_1(net)\n",
    "        net = self.conv3_2(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.conv4_1(net)\n",
    "        net = self.conv4_2(net)\n",
    "        net = self.pool4(net)\n",
    "\n",
    "        net = self.flatten(net)\n",
    "        net = self.fc1_1(net)\n",
    "        net = self.fc1_2(net)\n",
    "        net = self.fc2(net)\n",
    "        \n",
    "        return net\n",
    "\n",
    "    def load_vggish_slim_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Loads a pre-trained VGGish-compatible checkpoint.\"\"\"\n",
    "        self.load_weights(checkpoint_path)\n",
    "\n",
    "vggish = VGGish()\n",
    "vggish.load_vggish_slim_checkpoint(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vg_gish_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vg_gish (VGGish)            multiple                  72141184  \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  66048     \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  65664     \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  2580      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,439,700\n",
      "Trainable params: 298,516\n",
      "Non-trainable params: 72,141,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import vggish_input\n",
    "\n",
    "class VGGishClassifier(tf.keras.Model):\n",
    "    def __init__(self, vggish_model, num_classes):\n",
    "        super(VGGishClassifier, self).__init__()\n",
    "        self.vggish_model = vggish_model\n",
    "        self.dense1 = Dense(512, activation='relu')\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dense3 = Dense(128, activation='relu')\n",
    "        self.skip1 = Dense(128, activation='relu')\n",
    "        self.dense4 = Dense(num_classes, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.vggish_model(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = self.skip1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = add([x, skip])\n",
    "        x = self.dense4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 20  # Set the number of classes as needed\n",
    "classifier_model = VGGishClassifier(vggish, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                         loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "# Prepare the input data and labels\n",
    "batch_size = 10\n",
    "num_frames = params.NUM_FRAMES\n",
    "num_bands = params.NUM_BANDS\n",
    "\n",
    "input_data = np.random.rand(batch_size, num_frames, num_bands, 1).astype(np.float32)\n",
    "# labels = np.random.randint(0, num_classes, size=(batch_size,))\n",
    "# force all labels to be the same\n",
    "labels = np.ones((batch_size,)) * 5\n",
    "\n",
    "classifier_model.build(input_shape=(None, params.NUM_FRAMES, params.NUM_BANDS, 1))\n",
    "classifier_model.summary()\n",
    "\n",
    "# Train the classifier model\n",
    "if False:\n",
    "    classifier_model.fit(input_data, labels, epochs=10)\n",
    "\n",
    "    predictions = classifier_model.predict(input_data)\n",
    "\n",
    "    print(f\"Predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, Add\n",
    "# import Rescaling\n",
    "from keras.layers.preprocessing.image_preprocessing import Rescaling\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Layer, MultiHeadAttention, Dense, LayerNormalization, Dropout, Reshape, Add\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(d_model),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class VGGishTransformerClassifier(tf.keras.Model):\n",
    "    def __init__(self, vggish_model, num_classes, num_heads=4, ff_dim=512):\n",
    "        super(VGGishTransformerClassifier, self).__init__()\n",
    "        self.vggish_model = vggish_model\n",
    "        self.reshape = Reshape((1, 128))  # Reshaping the output to (batch_size, 1, 128)\n",
    "        self.transformer_block = TransformerBlock(d_model=128, num_heads=num_heads, ff_dim=ff_dim)\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.skip1 = Dense(128, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense2 = Dense(num_classes, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.vggish_model(inputs)\n",
    "        x = self.reshape(x)\n",
    "        x = self.transformer_block(x)\n",
    "        x = tf.squeeze(x, axis=1)  # Squeezing the output back to (batch_size, 128)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = self.skip1(x)\n",
    "        x = Add()([x, skip])\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000135_483840' '000139_119040' '000141_153600' '000144_30720'\n",
      " '000145_172800']\n",
      "['000308_61440' '000312_184320' '000319_145920' '000321_218880'\n",
      " '000327_88320']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# train csv path\n",
    "train_csv_path = 'openmic-2018/partitions/split01_train.csv'\n",
    "# test csv path\n",
    "test_csv_path = 'openmic-2018/partitions/split01_test.csv'\n",
    "\n",
    "# open csvs\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# convert to numpy arrays\n",
    "train_df = train_df.to_numpy()\n",
    "test_df = test_df.to_numpy()\n",
    "\n",
    "# make each a single list\n",
    "train_df = train_df.flatten()\n",
    "test_df = test_df.flatten()\n",
    "\n",
    "# print the first 5 rows of the train and test dataframes\n",
    "print(train_df[:5])\n",
    "print(test_df[:5])\n",
    "\n",
    "# only use the first 10% of each csv\n",
    "train_df = train_df[:int(len(train_df) * 0.5)]\n",
    "test_df = test_df[:int(len(test_df) * 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (74570, 96, 64, 1)\n",
      "Labels shape: (74570, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'spectrograms'\n",
    "labels_path = 'labels.csv'\n",
    "\n",
    "# Read the labels CSV file\n",
    "# ['filename' 'clarinet' 'flute' 'trumpet' 'saxophone' 'voice' 'accordion' 'ukulele' 'mallet_percussion' 'piano' 'guitar' 'mandolin' 'banjo' 'synthesizer' 'trombone' 'organ' 'drums' 'bass' 'cymbals' 'cello' 'violin']\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "# Get the list of all the filenames\n",
    "filenames = labels_df['filename'].values.tolist()\n",
    "\n",
    "# load the spectrograms and labels\n",
    "spectrograms_train = []\n",
    "labels_train = []\n",
    "\n",
    "spectrograms_test = []\n",
    "labels_test = []\n",
    "\n",
    "for filename in filenames:\n",
    "    # if the filename is not in the train or test dataframe, skip it\n",
    "    if filename not in train_df and filename not in test_df:\n",
    "        continue\n",
    "\n",
    "    # load the spectrogram\n",
    "    spectrogram = np.load(os.path.join(dataset_path, filename + '.npy'))\n",
    "\n",
    "    # the fist index is the filename, the next 20 are the labels and the last 20 are the masks\n",
    "    label = labels_df[labels_df['filename'] == filename].values.tolist()[0][1:21]\n",
    "    mask = labels_df[labels_df['filename'] == filename].values.tolist()[0][21:]\n",
    "\n",
    "    # make a pair of the spectrogram and the label\n",
    "    combined = list(zip(label, mask))\n",
    "\n",
    "    # append each second seperatly\n",
    "    if filename in train_df:\n",
    "        for i in range(10):\n",
    "            spectrograms_train.append(spectrogram[i])\n",
    "            labels_train.append(combined)\n",
    "    elif filename in test_df:\n",
    "        for i in range(10):\n",
    "            spectrograms_test.append(spectrogram[i])\n",
    "            labels_test.append(combined)\n",
    "    else:\n",
    "        continue\n",
    "        # print(f\"Filename {filename} not found in train or test dataframes\")\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "spectrograms_train = np.array(spectrograms_train)\n",
    "labels_train = np.array(labels_train)\n",
    "\n",
    "spectrograms_test = np.array(spectrograms_test)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "#spectrograms = spectrograms.reshape(spectrograms.shape[0], num_frames, num_bands, 1)\n",
    "spectrograms_test = np.expand_dims(spectrograms_test, axis=-1)\n",
    "spectrograms_train = np.expand_dims(spectrograms_train, axis=-1)\n",
    "\n",
    "\n",
    "print(f\"Spectrograms shape: {spectrograms_train.shape}\")\n",
    "print(f\"Labels shape: {labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (74570, 96, 64, 1)\n",
      "y_train shape: (74570, 20)\n",
      "X_test shape: (25420, 96, 64, 1)\n",
      "y_test shape: (25420, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(spectrograms, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = spectrograms_train\n",
    "y_train = labels_train\n",
    "\n",
    "X_test = spectrograms_test\n",
    "y_test = labels_test\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vg_gish_transformer_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vg_gish (VGGish)            multiple                  72141184  \n",
      "                                                                 \n",
      " reshape (Reshape)           multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 396032    \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  16512     \n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  16512     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            multiple                  2580      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,572,820\n",
      "Trainable params: 431,636\n",
      "Non-trainable params: 72,141,184\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 02:21:54.347843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8204\n",
      "2023-05-09 02:21:59.232229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================] - 31s 38ms/step - loss: 0.3417 - accuracy: 0.0866 - f1: 0.0021 - val_loss: 0.3231 - val_accuracy: 0.1127 - val_f1: 0.0000e+00\n",
      "Epoch 2/32\n",
      "583/583 [==============================] - 23s 39ms/step - loss: 0.3245 - accuracy: 0.1201 - f1: 0.0057 - val_loss: 0.3167 - val_accuracy: 0.1452 - val_f1: 0.0032\n",
      "Epoch 3/32\n",
      "583/583 [==============================] - 23s 40ms/step - loss: 0.3173 - accuracy: 0.1370 - f1: 0.0170 - val_loss: 0.3122 - val_accuracy: 0.1585 - val_f1: 0.0054\n",
      "Epoch 4/32\n",
      "583/583 [==============================] - 23s 40ms/step - loss: 0.3135 - accuracy: 0.1478 - f1: 0.0346 - val_loss: 0.3124 - val_accuracy: 0.1456 - val_f1: 0.0173\n",
      "Epoch 5/32\n",
      "583/583 [==============================] - 24s 40ms/step - loss: 0.3111 - accuracy: 0.1528 - f1: 0.0433 - val_loss: 0.3124 - val_accuracy: 0.1540 - val_f1: 0.0172\n",
      "Epoch 6/32\n",
      "583/583 [==============================] - 68s 116ms/step - loss: 0.3094 - accuracy: 0.1610 - f1: 0.0522 - val_loss: 0.3100 - val_accuracy: 0.1734 - val_f1: 0.0219\n",
      "Epoch 7/32\n",
      "583/583 [==============================] - 68s 117ms/step - loss: 0.3079 - accuracy: 0.1644 - f1: 0.0566 - val_loss: 0.3064 - val_accuracy: 0.1707 - val_f1: 0.0229\n",
      "Epoch 8/32\n",
      "583/583 [==============================] - 55s 95ms/step - loss: 0.3067 - accuracy: 0.1649 - f1: 0.0636 - val_loss: 0.3078 - val_accuracy: 0.1674 - val_f1: 0.0308\n",
      "Epoch 9/32\n",
      "583/583 [==============================] - 23s 40ms/step - loss: 0.3058 - accuracy: 0.1699 - f1: 0.0676 - val_loss: 0.3069 - val_accuracy: 0.1667 - val_f1: 0.0171\n",
      "Epoch 10/32\n",
      "583/583 [==============================] - 44s 75ms/step - loss: 0.3045 - accuracy: 0.1715 - f1: 0.0743 - val_loss: 0.3100 - val_accuracy: 0.1644 - val_f1: 0.0182\n",
      "Epoch 11/32\n",
      "583/583 [==============================] - 68s 117ms/step - loss: 0.3035 - accuracy: 0.1742 - f1: 0.0799 - val_loss: 0.3080 - val_accuracy: 0.1564 - val_f1: 0.0301\n",
      "Epoch 12/32\n",
      "583/583 [==============================] - 69s 118ms/step - loss: 0.3024 - accuracy: 0.1792 - f1: 0.0842 - val_loss: 0.3059 - val_accuracy: 0.1705 - val_f1: 0.0278\n",
      "Epoch 13/32\n",
      "583/583 [==============================] - 69s 118ms/step - loss: 0.3017 - accuracy: 0.1811 - f1: 0.0886 - val_loss: 0.3053 - val_accuracy: 0.1699 - val_f1: 0.0336\n",
      "Epoch 14/32\n",
      "583/583 [==============================] - 71s 122ms/step - loss: 0.3007 - accuracy: 0.1819 - f1: 0.0924 - val_loss: 0.3064 - val_accuracy: 0.1659 - val_f1: 0.0264\n",
      "Epoch 15/32\n",
      "583/583 [==============================] - 70s 121ms/step - loss: 0.2997 - accuracy: 0.1857 - f1: 0.0955 - val_loss: 0.3051 - val_accuracy: 0.1779 - val_f1: 0.0279\n",
      "Epoch 16/32\n",
      "583/583 [==============================] - 70s 120ms/step - loss: 0.2991 - accuracy: 0.1858 - f1: 0.0997 - val_loss: 0.3054 - val_accuracy: 0.1701 - val_f1: 0.0270\n",
      "Epoch 17/32\n",
      "583/583 [==============================] - 71s 122ms/step - loss: 0.2987 - accuracy: 0.1862 - f1: 0.1031 - val_loss: 0.3061 - val_accuracy: 0.1791 - val_f1: 0.0256\n",
      "Epoch 18/32\n",
      "583/583 [==============================] - 69s 118ms/step - loss: 0.2976 - accuracy: 0.1893 - f1: 0.1079 - val_loss: 0.3056 - val_accuracy: 0.1784 - val_f1: 0.0231\n",
      "Epoch 19/32\n",
      "583/583 [==============================] - 69s 118ms/step - loss: 0.2969 - accuracy: 0.1919 - f1: 0.1108 - val_loss: 0.3050 - val_accuracy: 0.1833 - val_f1: 0.0270\n",
      "Epoch 20/32\n",
      "583/583 [==============================] - 68s 117ms/step - loss: 0.2963 - accuracy: 0.1942 - f1: 0.1143 - val_loss: 0.3043 - val_accuracy: 0.1760 - val_f1: 0.0255\n",
      "Epoch 21/32\n",
      "583/583 [==============================] - 70s 120ms/step - loss: 0.2954 - accuracy: 0.1957 - f1: 0.1189 - val_loss: 0.3048 - val_accuracy: 0.1734 - val_f1: 0.0265\n",
      "Epoch 22/32\n",
      "583/583 [==============================] - 68s 116ms/step - loss: 0.2945 - accuracy: 0.1966 - f1: 0.1228 - val_loss: 0.3040 - val_accuracy: 0.1802 - val_f1: 0.0293\n",
      "Epoch 23/32\n",
      "583/583 [==============================] - 69s 118ms/step - loss: 0.2941 - accuracy: 0.1993 - f1: 0.1238 - val_loss: 0.3049 - val_accuracy: 0.1787 - val_f1: 0.0370\n",
      "Epoch 24/32\n",
      "583/583 [==============================] - 69s 118ms/step - loss: 0.2932 - accuracy: 0.2009 - f1: 0.1297 - val_loss: 0.3051 - val_accuracy: 0.1749 - val_f1: 0.0333\n",
      "Epoch 25/32\n",
      "583/583 [==============================] - 68s 117ms/step - loss: 0.2923 - accuracy: 0.2022 - f1: 0.1359 - val_loss: 0.3045 - val_accuracy: 0.1829 - val_f1: 0.0306\n",
      "Epoch 26/32\n",
      "583/583 [==============================] - 70s 120ms/step - loss: 0.2919 - accuracy: 0.2048 - f1: 0.1372 - val_loss: 0.3043 - val_accuracy: 0.1838 - val_f1: 0.0340\n",
      "Epoch 27/32\n",
      "583/583 [==============================] - 69s 118ms/step - loss: 0.2912 - accuracy: 0.2046 - f1: 0.1421 - val_loss: 0.3052 - val_accuracy: 0.1748 - val_f1: 0.0310\n",
      "Epoch 28/32\n",
      "583/583 [==============================] - 68s 116ms/step - loss: 0.2905 - accuracy: 0.2068 - f1: 0.1446 - val_loss: 0.3053 - val_accuracy: 0.1766 - val_f1: 0.0282\n",
      "Epoch 29/32\n",
      "583/583 [==============================] - 68s 116ms/step - loss: 0.2896 - accuracy: 0.2105 - f1: 0.1483 - val_loss: 0.3052 - val_accuracy: 0.1768 - val_f1: 0.0384\n",
      "Epoch 30/32\n",
      "583/583 [==============================] - 67s 116ms/step - loss: 0.2889 - accuracy: 0.2096 - f1: 0.1538 - val_loss: 0.3035 - val_accuracy: 0.1799 - val_f1: 0.0319\n",
      "Epoch 31/32\n",
      "583/583 [==============================] - 68s 117ms/step - loss: 0.2880 - accuracy: 0.2124 - f1: 0.1567 - val_loss: 0.3040 - val_accuracy: 0.1867 - val_f1: 0.0347\n",
      "Epoch 32/32\n",
      "583/583 [==============================] - 69s 118ms/step - loss: 0.2875 - accuracy: 0.2130 - f1: 0.1602 - val_loss: 0.3047 - val_accuracy: 0.1688 - val_f1: 0.0330\n",
      "795/795 [==============================] - 32s 37ms/step\n",
      "Predictions shape: (25420, 20)\n",
      "First prediction: [0.08 0.04 0.14 0.13 0.05 0.05 0.1  0.06 0.11 0.12 0.08 0.09 0.07 0.17\n",
      " 0.1  0.05 0.22 0.03 0.37 0.06]\n",
      "First label:      [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# import f1\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "@tf.function\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Computes the F1 score.\n",
    "\n",
    "    Computes the F1 score between the labels and predictions.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=0)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=0)\n",
    "\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return K.mean(f1_val)\n",
    "\n",
    "num_classes = 20  # Set the number of classes as needed\n",
    "# classifier_model = VGGishClassifier(vggish, num_classes)\n",
    "classifier_model = VGGishTransformerClassifier(vggish, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                         loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                         metrics=['accuracy', f1])\n",
    "\n",
    "classifier_model.build(input_shape=(None, params.NUM_FRAMES, params.NUM_BANDS, 1))\n",
    "\n",
    "classifier_model.summary()\n",
    "\n",
    "\n",
    "history = classifier_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=32, batch_size=128)\n",
    "\n",
    "predictions = classifier_model.predict(X_test)\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "\n",
    "# print the first prediction rounded to 2 decimal places\n",
    "print(f\"First prediction: {np.round(predictions[5], 2)}\")\n",
    "print(f\"First label:      {y_test[5]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
