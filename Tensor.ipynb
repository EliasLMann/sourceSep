{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:12:46.820301: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 15:12:47.411703: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-09 15:12:48.760342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 15:12:48.760587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 15:12:48.760593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling2D, TimeDistributed, Conv1D, Conv2D, GlobalAveragePooling1D, MaxPool2D, Flatten, add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# silence tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# getting rid of the warning messages about optimizer graph\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "Tensorflow version: 2.11.0\n",
      "Keras version: 2.11.0\n",
      "Using NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:12:50.687453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:51.133772: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:51.133817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:51.175315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:51.175506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:51.175556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.323080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.323226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.323235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 15:12:54.323274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.323397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-05-09 15:12:54.334332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# print Tensorflow and CUDA information\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    " \n",
    "if tf.test.gpu_device_name():\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "    name = details.get('device_name', 'Unknown GPU')\n",
    "    \n",
    "    print(f\"Using {name}\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:12:54.406692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.406770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.406786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.407473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.407493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 15:12:54.407524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 15:12:54.407614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import vggish_params as params\n",
    "\n",
    "\n",
    "path = 'vggish_model.ckpt'\n",
    "\n",
    "class VGGish(tf.keras.Model):\n",
    "    def __init__(self, training=False):\n",
    "        super(VGGish, self).__init__()\n",
    "        self.training = training\n",
    "\n",
    "        # The VGG stack of alternating convolutions and max-pools.\n",
    "        self.conv1 = Conv2D(64, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool1 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv2 = Conv2D(128, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool2 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv3_1 = Conv2D(256, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.conv3_2 = Conv2D(256, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool3 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv4_1 = Conv2D(512, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.conv4_2 = Conv2D(512, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool4 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "\n",
    "        # Flatten before entering fully-connected layers\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1_1 = Dense(4096, activation=tf.nn.relu, trainable=self.training)\n",
    "        self.fc1_2 = Dense(4096, activation=tf.nn.relu, trainable=self.training)\n",
    "        # The embedding layer.\n",
    "        self.fc2 = Dense(params.EMBEDDING_SIZE, activation=None, trainable=self.training)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3_1(net)\n",
    "        net = self.conv3_2(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.conv4_1(net)\n",
    "        net = self.conv4_2(net)\n",
    "        net = self.pool4(net)\n",
    "\n",
    "        net = self.flatten(net)\n",
    "        net = self.fc1_1(net)\n",
    "        net = self.fc1_2(net)\n",
    "        net = self.fc2(net)\n",
    "        \n",
    "        return net\n",
    "\n",
    "    def load_vggish_slim_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Loads a pre-trained VGGish-compatible checkpoint.\"\"\"\n",
    "        self.load_weights(checkpoint_path)\n",
    "\n",
    "vggish = VGGish()\n",
    "vggish.load_vggish_slim_checkpoint(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vg_gish_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vg_gish (VGGish)            multiple                  72141184  \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  66048     \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  65664     \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  2580      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,439,700\n",
      "Trainable params: 298,516\n",
      "Non-trainable params: 72,141,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import vggish_input\n",
    "\n",
    "class VGGishClassifier(tf.keras.Model):\n",
    "    def __init__(self, vggish_model, num_classes):\n",
    "        super(VGGishClassifier, self).__init__()\n",
    "        self.vggish_model = vggish_model\n",
    "        self.dense1 = Dense(512, activation='relu')\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dense3 = Dense(128, activation='relu')\n",
    "        self.skip1 = Dense(128, activation='relu')\n",
    "        self.dense4 = Dense(num_classes, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.vggish_model(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = self.skip1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = add([x, skip])\n",
    "        x = self.dense4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 20  # Set the number of classes as needed\n",
    "classifier_model = VGGishClassifier(vggish, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                         loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "# Prepare the input data and labels\n",
    "batch_size = 10\n",
    "num_frames = params.NUM_FRAMES\n",
    "num_bands = params.NUM_BANDS\n",
    "\n",
    "input_data = np.random.rand(batch_size, num_frames, num_bands, 1).astype(np.float32)\n",
    "# labels = np.random.randint(0, num_classes, size=(batch_size,))\n",
    "# force all labels to be the same\n",
    "labels = np.ones((batch_size,)) * 5\n",
    "\n",
    "classifier_model.build(input_shape=(None, params.NUM_FRAMES, params.NUM_BANDS, 1))\n",
    "classifier_model.summary()\n",
    "\n",
    "# Train the classifier model\n",
    "if False:\n",
    "    classifier_model.fit(input_data, labels, epochs=10)\n",
    "\n",
    "    predictions = classifier_model.predict(input_data)\n",
    "\n",
    "    print(f\"Predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, Add\n",
    "# import Rescaling\n",
    "from keras.layers.preprocessing.image_preprocessing import Rescaling\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Layer, MultiHeadAttention, Dense, LayerNormalization, Dropout, Reshape, Add\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(d_model),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class VGGishTransformerClassifier(tf.keras.Model):\n",
    "    def __init__(self, vggish_model, num_classes, num_heads=4, ff_dim=512):\n",
    "        super(VGGishTransformerClassifier, self).__init__()\n",
    "        self.vggish_model = vggish_model\n",
    "        self.reshape = Reshape((1, 128))  # Reshaping the output to (batch_size, 1, 128)\n",
    "        self.transformer_block = TransformerBlock(d_model=128, num_heads=num_heads, ff_dim=ff_dim)\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.skip1 = Dense(128, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense2 = Dense(num_classes, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.vggish_model(inputs)\n",
    "        x = self.reshape(x)\n",
    "        x = self.transformer_block(x)\n",
    "        x = tf.squeeze(x, axis=1)  # Squeezing the output back to (batch_size, 128)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = self.skip1(x)\n",
    "        x = Add()([x, skip])\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000135_483840' '000139_119040' '000141_153600' '000144_30720'\n",
      " '000145_172800']\n",
      "['000308_61440' '000312_184320' '000319_145920' '000321_218880'\n",
      " '000327_88320']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# train csv path\n",
    "train_csv_path = 'openmic-2018/partitions/split01_train.csv'\n",
    "# test csv path\n",
    "test_csv_path = 'openmic-2018/partitions/split01_test.csv'\n",
    "\n",
    "# open csvs\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# convert to numpy arrays\n",
    "train_df = train_df.to_numpy()\n",
    "test_df = test_df.to_numpy()\n",
    "\n",
    "# make each a single list\n",
    "train_df = train_df.flatten()\n",
    "test_df = test_df.flatten()\n",
    "\n",
    "# print the first 5 rows of the train and test dataframes\n",
    "print(train_df[:5])\n",
    "print(test_df[:5])\n",
    "\n",
    "# only use the first 10% of each csv\n",
    "train_df = train_df[:int(len(train_df) * 1)]\n",
    "test_df = test_df[:int(len(test_df) * 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (22370, 96, 64, 1)\n",
      "Labels shape: (22370, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'spectrograms'\n",
    "labels_path = 'labels.csv'\n",
    "\n",
    "# Read the labels CSV file\n",
    "# ['filename' 'clarinet' 'flute' 'trumpet' 'saxophone' 'voice' 'accordion' 'ukulele' 'mallet_percussion' 'piano' 'guitar' 'mandolin' 'banjo' 'synthesizer' 'trombone' 'organ' 'drums' 'bass' 'cymbals' 'cello' 'violin']\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "# Get the list of all the filenames\n",
    "filenames = labels_df['filename'].values.tolist()\n",
    "\n",
    "# load the spectrograms and labels\n",
    "spectrograms_train = []\n",
    "labels_train = []\n",
    "\n",
    "spectrograms_test = []\n",
    "labels_test = []\n",
    "\n",
    "for filename in filenames:\n",
    "    # if the filename is not in the train or test dataframe, skip it\n",
    "    if filename not in train_df and filename not in test_df:\n",
    "        continue\n",
    "\n",
    "    # load the spectrogram\n",
    "    spectrogram = np.load(os.path.join(dataset_path, filename + '.npy'))\n",
    "\n",
    "    # the fist index is the filename, the next 20 are the labels and the last 20 are the masks\n",
    "    label = labels_df[labels_df['filename'] == filename].values.tolist()[0][1:21]\n",
    "    mask = labels_df[labels_df['filename'] == filename].values.tolist()[0][21:]\n",
    "\n",
    "    # threshold the labels\n",
    "    label = np.array(label) > 0.5\n",
    "\n",
    "    # make a pair of the spectrogram and the label\n",
    "    combined = list(zip(label, mask))\n",
    "\n",
    "    # append each second seperatly\n",
    "    if filename in train_df:\n",
    "        for i in range(10):\n",
    "            spectrograms_train.append(spectrogram[i])\n",
    "            labels_train.append(combined)\n",
    "    elif filename in test_df:\n",
    "        for i in range(10):\n",
    "            spectrograms_test.append(spectrogram[i])\n",
    "            labels_test.append(combined)\n",
    "    else:\n",
    "        continue\n",
    "        # print(f\"Filename {filename} not found in train or test dataframes\")\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "spectrograms_train = np.array(spectrograms_train)\n",
    "labels_train = np.array(labels_train)\n",
    "\n",
    "spectrograms_test = np.array(spectrograms_test)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "#spectrograms = spectrograms.reshape(spectrograms.shape[0], num_frames, num_bands, 1)\n",
    "spectrograms_test = np.expand_dims(spectrograms_test, axis=-1)\n",
    "spectrograms_train = np.expand_dims(spectrograms_train, axis=-1)\n",
    "\n",
    "\n",
    "print(f\"Spectrograms shape: {spectrograms_train.shape}\")\n",
    "print(f\"Labels shape: {labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (22370, 96, 64, 1)\n",
      "y_train shape: (22370, 20, 2)\n",
      "X_test shape: (7620, 96, 64, 1)\n",
      "y_test shape: (7620, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def m_binary_crossentropy(y_true, y_pred):\n",
    "    # Separate labels and masks from y_true\n",
    "    labels = y_true[..., 0]\n",
    "    \n",
    "    # Compute the binary crossentropy\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    loss = bce(labels, y_pred)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def BCEp(y_true, y_pred, alpha=1.0, beta=0.0, gamma=-1.0):\n",
    "    # y_true and y_pred have shape (batch_size, 20)\n",
    "\n",
    "    # Get the ground truth for each label\n",
    "    y_true_labels = y_true[..., 0]\n",
    "\n",
    "    # Get the mask for each label\n",
    "    y_true_masks = y_true[..., 1]\n",
    "\n",
    "    # ground truth * log(prediction) + (1 - ground truth) * log(1 - prediction)\n",
    "    # unreduced_bce_func = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    # bce = unreduced_bce_func(y_true_labels, y_pred)\n",
    "\n",
    "    bce = y_true_labels * tf.math.log(y_pred) + (1 - y_true_labels) * tf.math.log(1 - y_pred)\n",
    "\n",
    "    # print shape\n",
    "    print(f\"bce shape: {bce.shape}\")\n",
    "\n",
    "    # mask the loss to zero for labels that are not present\n",
    "    masked_bce = bce * y_true_masks\n",
    "\n",
    "    # compute proportion of labels that are present\n",
    "    present_labels = tf.reduce_sum(y_true_masks, axis=1) / 20.0\n",
    "\n",
    "    # nomalize the present labels then divide by the number of labels\n",
    "    normalized_present_labels = (alpha * (present_labels ** gamma) + beta) / 20.0\n",
    " \n",
    "\n",
    "    print(f\"normalized_present_labels shape: {normalized_present_labels}\")\n",
    "\n",
    "    # reduce the loss\n",
    "    loss = tf.reduce_sum(masked_bce, axis=1) * normalized_present_labels\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def m_accuracy(y_true, y_pred):\n",
    "    # Separate labels and masks from y_true. The masks should be ignored.\n",
    "    labels = y_true[..., 0]\n",
    "    masks = y_true[..., 1]\n",
    "\n",
    "    # Threshold predictions to convert them to binary values (assuming 0.5 as the threshold)\n",
    "    binary_pred = tf.cast(tf.greater_equal(y_pred, 0.5), tf.float32)\n",
    "\n",
    "    # Compute the element-wise equality between binary_pred and y_true\n",
    "    correct_predictions = tf.cast(tf.equal(binary_pred, labels), tf.float32)\n",
    "\n",
    "    # multiply by the mask\n",
    "    correct_predictions = correct_predictions * masks\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = tf.reduce_sum(correct_predictions) / tf.reduce_sum(masks)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "@tf.function\n",
    "def m_f1(y_true, y_pred):\n",
    "    # Separate labels and masks from y_true\n",
    "    labels = y_true[..., 0]\n",
    "    masks = y_true[..., 1]\n",
    "\n",
    "    # Threshold predictions to convert them to binary values (assuming 0.5 as the threshold)\n",
    "    binary_pred = tf.cast(tf.greater_equal(y_pred, 0.5), tf.float32)\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positives = tf.reduce_sum(binary_pred * labels * masks)\n",
    "    false_positives = tf.reduce_sum(binary_pred * (1 - labels) * masks)\n",
    "    false_negatives = tf.reduce_sum((1 - binary_pred) * labels * masks)\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives + 1e-8)\n",
    "    recall = true_positives / (true_positives + false_negatives + 1e-8)\n",
    "\n",
    "    # Calculate the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "X_train = spectrograms_train\n",
    "y_train = labels_train\n",
    "\n",
    "X_test = spectrograms_test\n",
    "y_test = labels_test\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vg_gish_transformer_classifier_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vg_gish (VGGish)            multiple                  72141184  \n",
      "                                                                 \n",
      " reshape_19 (Reshape)        multiple                  0         \n",
      "                                                                 \n",
      " transformer_block_19 (Trans  multiple                 396032    \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " dense_105 (Dense)           multiple                  16512     \n",
      "                                                                 \n",
      " dense_106 (Dense)           multiple                  16512     \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           multiple                  2580      \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,572,820\n",
      "Trainable params: 431,636\n",
      "Non-trainable params: 72,141,184\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "175/175 [==============================] - 10s 44ms/step - loss: 0.2133 - m_accuracy: 0.5516 - m_f1: 0.0114 - val_loss: 0.1804 - val_m_accuracy: 0.5583 - val_m_f1: 0.0000e+00\n",
      "Epoch 2/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1836 - m_accuracy: 0.5555 - m_f1: 0.0086 - val_loss: 0.1737 - val_m_accuracy: 0.5583 - val_m_f1: 0.0000e+00\n",
      "Epoch 3/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1767 - m_accuracy: 0.5589 - m_f1: 0.0254 - val_loss: 0.1708 - val_m_accuracy: 0.5640 - val_m_f1: 0.0296\n",
      "Epoch 4/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1717 - m_accuracy: 0.5613 - m_f1: 0.0370 - val_loss: 0.1705 - val_m_accuracy: 0.5708 - val_m_f1: 0.0597\n",
      "Epoch 5/32\n",
      "175/175 [==============================] - 7s 39ms/step - loss: 0.1696 - m_accuracy: 0.5612 - m_f1: 0.0374 - val_loss: 0.1668 - val_m_accuracy: 0.5701 - val_m_f1: 0.0583\n",
      "Epoch 6/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1665 - m_accuracy: 0.5644 - m_f1: 0.0504 - val_loss: 0.1707 - val_m_accuracy: 0.5605 - val_m_f1: 0.0100\n",
      "Epoch 7/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1642 - m_accuracy: 0.5656 - m_f1: 0.0547 - val_loss: 0.1684 - val_m_accuracy: 0.5837 - val_m_f1: 0.1141\n",
      "Epoch 8/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1622 - m_accuracy: 0.5686 - m_f1: 0.0686 - val_loss: 0.1650 - val_m_accuracy: 0.5645 - val_m_f1: 0.0317\n",
      "Epoch 9/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1610 - m_accuracy: 0.5687 - m_f1: 0.0687 - val_loss: 0.1662 - val_m_accuracy: 0.5702 - val_m_f1: 0.0573\n",
      "Epoch 10/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1598 - m_accuracy: 0.5701 - m_f1: 0.0742 - val_loss: 0.1659 - val_m_accuracy: 0.5775 - val_m_f1: 0.0894\n",
      "Epoch 11/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1583 - m_accuracy: 0.5721 - m_f1: 0.0833 - val_loss: 0.1628 - val_m_accuracy: 0.5798 - val_m_f1: 0.1023\n",
      "Epoch 12/32\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.1570 - m_accuracy: 0.5738 - m_f1: 0.0905 - val_loss: 0.1639 - val_m_accuracy: 0.5813 - val_m_f1: 0.1083\n",
      "Epoch 13/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1566 - m_accuracy: 0.5754 - m_f1: 0.0966 - val_loss: 0.1629 - val_m_accuracy: 0.5689 - val_m_f1: 0.0571\n",
      "Epoch 14/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1561 - m_accuracy: 0.5759 - m_f1: 0.0991 - val_loss: 0.1631 - val_m_accuracy: 0.5852 - val_m_f1: 0.1198\n",
      "Epoch 15/32\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 0.1548 - m_accuracy: 0.5771 - m_f1: 0.1032 - val_loss: 0.1618 - val_m_accuracy: 0.5783 - val_m_f1: 0.0924\n",
      "Epoch 16/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1532 - m_accuracy: 0.5798 - m_f1: 0.1153 - val_loss: 0.1625 - val_m_accuracy: 0.5763 - val_m_f1: 0.0876\n",
      "Epoch 17/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1527 - m_accuracy: 0.5825 - m_f1: 0.1251 - val_loss: 0.1625 - val_m_accuracy: 0.5766 - val_m_f1: 0.0905\n",
      "Epoch 18/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1524 - m_accuracy: 0.5818 - m_f1: 0.1224 - val_loss: 0.1622 - val_m_accuracy: 0.5818 - val_m_f1: 0.1086\n",
      "Epoch 19/32\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.1514 - m_accuracy: 0.5847 - m_f1: 0.1356 - val_loss: 0.1622 - val_m_accuracy: 0.5769 - val_m_f1: 0.0874\n",
      "Epoch 20/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1511 - m_accuracy: 0.5844 - m_f1: 0.1361 - val_loss: 0.1594 - val_m_accuracy: 0.5835 - val_m_f1: 0.1153\n",
      "Epoch 21/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1500 - m_accuracy: 0.5855 - m_f1: 0.1392 - val_loss: 0.1625 - val_m_accuracy: 0.5879 - val_m_f1: 0.1377\n",
      "Epoch 22/32\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.1496 - m_accuracy: 0.5866 - m_f1: 0.1449 - val_loss: 0.1621 - val_m_accuracy: 0.5857 - val_m_f1: 0.1241\n",
      "Epoch 23/32\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.1485 - m_accuracy: 0.5884 - m_f1: 0.1504 - val_loss: 0.1631 - val_m_accuracy: 0.5766 - val_m_f1: 0.0831\n",
      "Epoch 24/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1480 - m_accuracy: 0.5893 - m_f1: 0.1536 - val_loss: 0.1617 - val_m_accuracy: 0.5777 - val_m_f1: 0.0955\n",
      "Epoch 25/32\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.1470 - m_accuracy: 0.5923 - m_f1: 0.1649 - val_loss: 0.1647 - val_m_accuracy: 0.5882 - val_m_f1: 0.1377\n",
      "Epoch 26/32\n",
      "175/175 [==============================] - 7s 39ms/step - loss: 0.1464 - m_accuracy: 0.5921 - m_f1: 0.1649 - val_loss: 0.1634 - val_m_accuracy: 0.5814 - val_m_f1: 0.1085\n",
      "Epoch 27/32\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.1457 - m_accuracy: 0.5935 - m_f1: 0.1716 - val_loss: 0.1642 - val_m_accuracy: 0.5854 - val_m_f1: 0.1347\n",
      "Epoch 28/32\n",
      " 35/175 [=====>........................] - ETA: 4s - loss: 0.1431 - m_accuracy: 0.5968 - m_f1: 0.1830"
     ]
    }
   ],
   "source": [
    "# import f1\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "num_classes = 20  # Set the number of classes as needed\n",
    "# classifier_model = VGGishClassifier(vggish, num_classes)\n",
    "classifier_model = VGGishTransformerClassifier(vggish, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                         loss=m_binary_crossentropy,\n",
    "                         metrics=[m_accuracy, m_f1])\n",
    "\n",
    "classifier_model.build(input_shape=(None, params.NUM_FRAMES, params.NUM_BANDS, 1))\n",
    "\n",
    "classifier_model.summary()\n",
    "\n",
    "history = classifier_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=32, batch_size=128)\n",
    "\n",
    "predictions = classifier_model.predict(X_test)\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "\n",
    "# print the first prediction rounded to 2 decimal places\n",
    "print(f\"First prediction: {np.round(predictions[0], 2)}\")\n",
    "print(f\"First label:      {y_test[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
