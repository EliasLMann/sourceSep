{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Separation Using Classifier Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 23:48:54.684878: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 23:48:56.640861: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cudnn-8.2.4.15-11.4-eluwegpwn6adr7hlku5p5wru5xzefpop/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cuda-11.4.4-ctldo35wmmwws3jbgwkgjjcjawddu3qz/lib64\n",
      "2023-05-09 23:48:56.641025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cudnn-8.2.4.15-11.4-eluwegpwn6adr7hlku5p5wru5xzefpop/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cuda-11.4.4-ctldo35wmmwws3jbgwkgjjcjawddu3qz/lib64\n",
      "2023-05-09 23:48:56.641038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, add\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vggish_params as params\n",
    "\n",
    "\n",
    "path = 'vggish_model.ckpt'\n",
    "\n",
    "class VGGish(tf.keras.Model):\n",
    "    def __init__(self, training=False):\n",
    "        super(VGGish, self).__init__()\n",
    "        self.training = training\n",
    "\n",
    "        # The VGG stack of alternating convolutions and max-pools.\n",
    "        self.conv1 = Conv2D(64, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool1 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv2 = Conv2D(128, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool2 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv3_1 = Conv2D(256, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.conv3_2 = Conv2D(256, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool3 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "        self.conv4_1 = Conv2D(512, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.conv4_2 = Conv2D(512, kernel_size=[3, 3], padding='same', activation=tf.nn.relu, trainable=self.training)\n",
    "        self.pool4 = MaxPool2D(pool_size=[2, 2], padding='same', trainable=self.training)\n",
    "\n",
    "        # Flatten before entering fully-connected layers\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1_1 = Dense(4096, activation=tf.nn.relu, trainable=self.training)\n",
    "        self.fc1_2 = Dense(4096, activation=tf.nn.relu, trainable=self.training)\n",
    "        # The embedding layer.\n",
    "        self.fc2 = Dense(params.EMBEDDING_SIZE, activation=None, trainable=self.training)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3_1(net)\n",
    "        net = self.conv3_2(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.conv4_1(net)\n",
    "        net = self.conv4_2(net)\n",
    "        net = self.pool4(net)\n",
    "\n",
    "        net = self.flatten(net)\n",
    "        net = self.fc1_1(net)\n",
    "        net = self.fc1_2(net)\n",
    "        net = self.fc2(net)\n",
    "        \n",
    "        return net\n",
    "\n",
    "    def load_vggish_slim_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Loads a pre-trained VGGish-compatible checkpoint.\"\"\"\n",
    "        self.load_weights(checkpoint_path)\n",
    "\n",
    "vggish = VGGish()\n",
    "vggish.load_vggish_slim_checkpoint(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000135_483840' '000139_119040' '000141_153600' '000144_30720'\n",
      " '000145_172800']\n",
      "['000308_61440' '000312_184320' '000319_145920' '000321_218880'\n",
      " '000327_88320']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# train csv path\n",
    "train_csv_path = 'openmic-2018/partitions/split01_train.csv'\n",
    "# test csv path\n",
    "test_csv_path = 'openmic-2018/partitions/split01_test.csv'\n",
    "\n",
    "# open csvs\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# convert to numpy arrays\n",
    "train_df = train_df.to_numpy()\n",
    "test_df = test_df.to_numpy()\n",
    "\n",
    "# make each a single list\n",
    "train_df = train_df.flatten()\n",
    "test_df = test_df.flatten()\n",
    "\n",
    "# print the first 5 rows of the train and test dataframes\n",
    "print(train_df[:5])\n",
    "print(test_df[:5])\n",
    "\n",
    "# only use the first 10% of each csv\n",
    "train_df = train_df[:int(len(train_df) * 1)]\n",
    "test_df = test_df[:int(len(test_df) * 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (149140, 96, 64, 1)\n",
      "Labels shape: (149140, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'spectrograms'\n",
    "labels_path = 'labels.csv'\n",
    "\n",
    "# Read the labels CSV file\n",
    "# ['filename' 'clarinet' 'flute' 'trumpet' 'saxophone' 'voice' 'accordion' 'ukulele' 'mallet_percussion' 'piano' 'guitar' 'mandolin' 'banjo' 'synthesizer' 'trombone' 'organ' 'drums' 'bass' 'cymbals' 'cello' 'violin']\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "# Get the list of all the filenames\n",
    "filenames = labels_df['filename'].values.tolist()\n",
    "\n",
    "# load the spectrograms and labels\n",
    "spectrograms_train = []\n",
    "labels_train = []\n",
    "\n",
    "spectrograms_test = []\n",
    "labels_test = []\n",
    "\n",
    "#check if pickle file exists\n",
    "if not os.path.isfile('pickle/spectrograms_train.pkl'):\n",
    "    \n",
    "    for filename in filenames:\n",
    "        # if the filename is not in the train or test dataframe, skip it\n",
    "        if filename not in train_df and filename not in test_df:\n",
    "            continue\n",
    "\n",
    "        # load the spectrogram\n",
    "        spectrogram = np.load(os.path.join(dataset_path, filename + '.npy'))\n",
    "\n",
    "        # the fist index is the filename, the next 20 are the labels and the last 20 are the masks\n",
    "        label = labels_df[labels_df['filename'] == filename].values.tolist()[0][1:21]\n",
    "        mask = labels_df[labels_df['filename'] == filename].values.tolist()[0][21:]\n",
    "\n",
    "        # threshold the labels\n",
    "        label = np.array(label) > 0.5\n",
    "\n",
    "        # make a pair of the spectrogram and the label\n",
    "        combined = list(zip(label, mask))\n",
    "\n",
    "        # append each second seperatly\n",
    "        if filename in train_df:\n",
    "            for i in range(10):\n",
    "                spectrograms_train.append(spectrogram[i])\n",
    "                labels_train.append(combined)\n",
    "        elif filename in test_df:\n",
    "            for i in range(10):\n",
    "                spectrograms_test.append(spectrogram[i])\n",
    "                labels_test.append(combined)\n",
    "        else:\n",
    "            continue\n",
    "            # print(f\"Filename {filename} not found in train or test dataframes\")\n",
    "\n",
    "    # convert the lists to numpy arrays\n",
    "    spectrograms_train = np.array(spectrograms_train)\n",
    "    labels_train = np.array(labels_train)\n",
    "\n",
    "    spectrograms_test = np.array(spectrograms_test)\n",
    "    labels_test = np.array(labels_test)\n",
    "\n",
    "    #spectrograms = spectrograms.reshape(spectrograms.shape[0], num_frames, num_bands, 1)\n",
    "    spectrograms_test = np.expand_dims(spectrograms_test, axis=-1)\n",
    "    spectrograms_train = np.expand_dims(spectrograms_train, axis=-1)\n",
    "\n",
    "    #pickle the spectrogram test and train data\n",
    "    pickle.dump(spectrograms_test, open('pickle/spectrograms_test.pkl', 'wb'))\n",
    "    pickle.dump(spectrograms_train, open('pickle/spectrograms_train.pkl', 'wb'))\n",
    "    #pickle the labels\n",
    "    pickle.dump(labels_test, open('pickle/labels_test.pkl', 'wb'))\n",
    "    pickle.dump(labels_train, open('pickle/labels_train.pkl', 'wb'))\n",
    "else:\n",
    "    #load the spectrogram test and train data\n",
    "    spectrograms_test = pickle.load(open('pickle/spectrograms_test.pkl', 'rb'))\n",
    "    spectrograms_train = pickle.load(open('pickle/spectrograms_train.pkl', 'rb'))\n",
    "    #load the labels\n",
    "    labels_test = pickle.load(open('pickle/labels_test.pkl', 'rb'))\n",
    "    labels_train = pickle.load(open('pickle/labels_train.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Spectrograms shape: {spectrograms_train.shape}\")\n",
    "print(f\"Labels shape: {labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vggish' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[39m=\u001b[39m vggish\u001b[39m.\u001b[39mpredict(spectrograms_train[:\u001b[39m10\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vggish' is not defined"
     ]
    }
   ],
   "source": [
    "x = vggish.predict(spectrograms_train[:10])\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_filters):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.num_filters = num_filters\n",
    "        self.build()\n",
    "\n",
    "    def conv_block(self, input, num_filters):\n",
    "        x = nn.Conv2d(input.shape[1], num_filters, 3, padding=1)(input)\n",
    "        x = nn.BatchNorm2d(num_filters)(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = nn.Conv2d(num_filters, num_filters, 3, padding=1)(x)\n",
    "        x = nn.BatchNorm2d(num_filters)(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        return x\n",
    "\n",
    "    def encoder_block(self, input, num_filters):\n",
    "        x = self.conv_block(input, num_filters)\n",
    "        p = nn.MaxPool2d(2)(x)\n",
    "        return x, p\n",
    "\n",
    "    def decoder_block(self, input, skip_features, num_filters):\n",
    "        x = nn.ConvTranspose2d(input.shape[1], num_filters, 2, stride=2)(input)\n",
    "        x = torch.cat([x, skip_features], dim=1)\n",
    "        x = self.conv_block(x, num_filters)\n",
    "        return x\n",
    "\n",
    "    def build(self):\n",
    "        # Input\n",
    "        self.inputs = nn.Parameter(torch.randn(1, self.input_shape[2], self.input_shape[0], self.input_shape[1]), requires_grad=True)\n",
    "\n",
    "        # Encoder\n",
    "        e1, p1 = self.encoder_block(self.inputs, self.num_filters)\n",
    "        e2, p2 = self.encoder_block(p1, self.num_filters*2)\n",
    "        e3, p3 = self.encoder_block(p2, self.num_filters*4)\n",
    "        e4, p4 = self.encoder_block(p3, self.num_filters*8)\n",
    "\n",
    "        # Bridge\n",
    "        b1 = self.conv_block(p4, self.num_filters*16)\n",
    "\n",
    "        # Decoder\n",
    "        d1 = self.decoder_block(b1, e4, self.num_filters*8)\n",
    "        d2 = self.decoder_block(d1, e3, self.num_filters*4)\n",
    "        d3 = self.decoder_block(d2, e2, self.num_filters*2)\n",
    "        d4 = self.decoder_block(d3, e1, self.num_filters)\n",
    "\n",
    "        # Output\n",
    "        self.outputs = nn.Sequential(\n",
    "            nn.Conv2d(self.num_filters, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        # Encoder\n",
    "        e1, p1 = self.encoder_block(self.inputs, self.num_filters)\n",
    "        e2, p2 = self.encoder_block(p1, self.num_filters*2)\n",
    "        e3, p3 = self.encoder_block(p2, self.num_filters*4)\n",
    "        e4, p4 = self.encoder_block(p3, self.num_filters*8)\n",
    "\n",
    "        # Bridge\n",
    "        b1 = self.conv_block(p4, self.num_filters*16)\n",
    "\n",
    "        # Decoder\n",
    "        d1 = self.decoder_block(b1, e4, self.num_filters*8)\n",
    "        d2 = self.decoder_block(d1, e3, self.num_filters*4)\n",
    "        d3 = self.decoder_block(d2, e2, self.num_filters*2)\n",
    "        d4 = self.decoder_block(d3, e1, self.num_filters)\n",
    "\n",
    "        # Output\n",
    "        return self.outputs(d4)\n",
    "\n",
    "    def summary(self):\n",
    "        print(self)\n",
    "\n",
    "    def compile(self, optimizer, loss):\n",
    "        self.optimizer = optimizer(self.parameters())\n",
    "        self.loss = loss\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs):\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for X, y in zip(X_train, y_train):\n",
    "                # Clear gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred = self.forward()\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = self.loss(y_pred, y)\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Update weights\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Update epoch loss\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            # Print epoch information\n",
    "            print(\"Epoch {} - loss: {}\".format(epoch, epoch_loss))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet Spectrogram Masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet:\n",
    "    def __init__(self, input_shape, num_filters):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_filters = num_filters\n",
    "        self.build()\n",
    "\n",
    "    def conv_block(self, input, num_filters):\n",
    "        x = Conv2D(num_filters, 3, padding=\"same\", activation=\"relu\")(input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(num_filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    def encoder_block(self, input, num_filters):\n",
    "        x = self.conv_block(input, num_filters)\n",
    "        p = MaxPooling2D((2, 2))(x)\n",
    "        return x, p\n",
    "\n",
    "    def decoder_block(self, input, skip_features, num_filters):\n",
    "        x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "        x = concatenate([x, skip_features], axis=3)\n",
    "        x = self.conv_block(x, num_filters)\n",
    "        return x\n",
    "\n",
    "    def build(self):\n",
    "        # Input\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "\n",
    "        # Encoder\n",
    "        e1, p1 = self.encoder_block(inputs, self.num_filters)\n",
    "        e2, p2 = self.encoder_block(p1, self.num_filters*2)\n",
    "        e3, p3 = self.encoder_block(p2, self.num_filters*4)\n",
    "        e4, p4 = self.encoder_block(p3, self.num_filters*8)\n",
    "\n",
    "        # Bridge\n",
    "        b1 = self.conv_block(p4, self.num_filters*16)\n",
    "\n",
    "        # Decoder\n",
    "        d1 = self.decoder_block(b1, e4, self.num_filters*8)\n",
    "        d2 = self.decoder_block(d1, e3, self.num_filters*4)\n",
    "        d3 = self.decoder_block(d2, e2, self.num_filters*2)\n",
    "        d4 = self.decoder_block(d3, e1, self.num_filters)\n",
    "\n",
    "        # Output\n",
    "        outputs = Conv2D(1, (1, 1), activation='sigmoid')(d4)\n",
    "\n",
    "        # Model\n",
    "        self.model = Model(inputs, outputs)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def compile(self, optimizer, loss, metrics=None):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 512, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 512, 128, 32  320         ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 512, 128, 32  128        ['conv2d_20[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 512, 128, 32  9248        ['batch_normalization_18[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 512, 128, 32  128        ['conv2d_21[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 256, 64, 32)  0          ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 256, 64, 64)  18496       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 256, 64, 64)  256        ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 256, 64, 64)  36928       ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 256, 64, 64)  256        ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 128, 32, 64)  0          ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 128, 32, 128  73856       ['max_pooling2d_5[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 128, 32, 128  512        ['conv2d_24[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 128, 32, 128  147584      ['batch_normalization_22[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 128, 32, 128  512        ['conv2d_25[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 64, 16, 128)  0          ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 64, 16, 256)  295168      ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 64, 16, 256)  1024       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 64, 16, 256)  590080      ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 64, 16, 256)  1024       ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 32, 8, 256)  0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 32, 8, 512)   1180160     ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 32, 8, 512)  2048        ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 32, 8, 512)   2359808     ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 32, 8, 512)  2048        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 64, 16, 256)  524544     ['batch_normalization_27[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 16, 512)  0           ['conv2d_transpose_4[0][0]',     \n",
      "                                                                  'batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 64, 16, 256)  1179904     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 64, 16, 256)  1024       ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 64, 16, 256)  590080      ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 64, 16, 256)  1024       ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 128, 32, 128  131200     ['batch_normalization_29[0][0]'] \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 32, 256  0           ['conv2d_transpose_5[0][0]',     \n",
      "                                )                                 'batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 128, 32, 128  295040      ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 128, 32, 128  512        ['conv2d_32[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 128, 32, 128  147584      ['batch_normalization_30[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 128, 32, 128  512        ['conv2d_33[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 256, 64, 64)  32832      ['batch_normalization_31[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 256, 64, 128  0           ['conv2d_transpose_6[0][0]',     \n",
      "                                )                                 'batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 256, 64, 64)  73792       ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 256, 64, 64)  256        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 256, 64, 64)  36928       ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 256, 64, 64)  256        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 512, 128, 32  8224       ['batch_normalization_33[0][0]'] \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 512, 128, 64  0           ['conv2d_transpose_7[0][0]',     \n",
      "                                )                                 'batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 512, 128, 32  18464       ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 512, 128, 32  128        ['conv2d_36[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 512, 128, 32  9248        ['batch_normalization_34[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 512, 128, 32  128        ['conv2d_37[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 512, 128, 1)  33          ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,771,297\n",
      "Trainable params: 7,765,409\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = UNet((512, 128, 1), 32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
