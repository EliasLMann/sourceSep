{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 22:24:08.789858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 22:24:08.899769: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-08 22:24:09.288457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-08 22:24:09.288550: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-08 22:24:09.288555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling2D, TimeDistributed, Conv1D, Conv2D, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "# import session\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# silence tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# getting rid of the warning messages about optimizer graph\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "Tensorflow version: 2.11.0\n",
      "Keras version: 2.11.0\n",
      "Using NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 22:24:09.942292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:09.958018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:09.958055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:09.962509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:09.962565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:09.962581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:10.393889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:10.393947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:10.393952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-08 22:24:10.393973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:24:10.394006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-05-08 22:24:10.395425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# print Tensorflow and CUDA information\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    " \n",
    "if tf.test.gpu_device_name():\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "    name = details.get('device_name', 'Unknown GPU')\n",
    "    \n",
    "    print(f\"Using {name}\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vggish_slim\n",
    "import vggish_params\n",
    "import vggish_input\n",
    "\n",
    "def CreateVGGishNetwork(hop_size=0.96):   # Hop size is in seconds.\n",
    "  \"\"\"Define VGGish model, load the checkpoint, and return a dictionary that points\n",
    "  to the different tensors defined by the model.\n",
    "  \"\"\"\n",
    "  vggish_slim.define_vggish_slim()\n",
    "  checkpoint_path = 'vggish_model.ckpt'\n",
    "  vggish_params.EXAMPLE_HOP_SECONDS = hop_size\n",
    "  vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
    "  features_tensor = sess.graph.get_tensor_by_name(\n",
    "      vggish_params.INPUT_TENSOR_NAME)\n",
    "  embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "      vggish_params.OUTPUT_TENSOR_NAME)\n",
    "  layers = {'conv1': 'vggish/conv1/Relu',\n",
    "            'pool1': 'vggish/pool1/MaxPool',\n",
    "            'conv2': 'vggish/conv2/Relu',\n",
    "            'pool2': 'vggish/pool2/MaxPool',\n",
    "            'conv3': 'vggish/conv3/conv3_2/Relu',\n",
    "            'pool3': 'vggish/pool3/MaxPool',\n",
    "            'conv4': 'vggish/conv4/conv4_2/Relu',\n",
    "            'pool4': 'vggish/pool4/MaxPool',\n",
    "            'fc1': 'vggish/fc1/fc1_2/Relu',\n",
    "            #'fc2': 'vggish/fc2/Relu',\n",
    "            'embedding': 'vggish/embedding',\n",
    "            'features': 'vggish/input_features',\n",
    "         }\n",
    "  g = tf.get_default_graph()\n",
    "  for k in layers:\n",
    "    layers[k] = g.get_tensor_by_name( layers[k] + ':0')\n",
    "  return {'features': features_tensor,\n",
    "          'embedding': embedding_tensor,\n",
    "          'layers': layers,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vggish_slim\n",
    "import vggish_params\n",
    "import vggish_input\n",
    "\n",
    "#import session\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "def ProcessWithVGGish(vgg, x, sr):\n",
    "  '''Run the VGGish model, starting with a sound (x) at sample rate\n",
    "  (sr). Return a whitened version of the embeddings. Sound must be scaled to be\n",
    "  floats between -1 and +1.'''\n",
    "  # Produce a batch of log mel spectrogram examples.\n",
    "  input_batch = vggish_input.waveform_to_examples(x, sr)\n",
    "  # print('Log Mel Spectrogram example: ', input_batch[0])\n",
    "  [embedding_batch] = sess.run([vgg['embedding']],\n",
    "                               feed_dict={vgg['features']: input_batch})\n",
    "  return embedding_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 22:26:05.090858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:26:05.091005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:26:05.091022: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:26:05.591415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:26:05.591471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-08 22:26:05.591550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-08 22:26:05.591588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original samples per second: 44100\n",
      "New samples per second: 16000\n",
      "Original waveform shape: (132300,)\n",
      "(203, 128)\n"
     ]
    }
   ],
   "source": [
    "# Test these new functions with the original test.\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "vgg = CreateVGGishNetwork(0.01)\n",
    "\n",
    "# Generate a 1 kHz sine wave at 44.1 kHz (we use a high sampling rate\n",
    "# to test resampling to 16 kHz during feature extraction).\n",
    "num_secs = 3\n",
    "freq = 1000\n",
    "sr = 44100\n",
    "t = np.linspace(0, num_secs, int(num_secs * sr))\n",
    "x = np.sin(2 * np.pi * freq * t)  # Unit amplitude input signal\n",
    "\n",
    "print('Original samples per second:', sr)\n",
    "print('New samples per second:', vggish_params.SAMPLE_RATE)\n",
    "# print shape\n",
    "print('Original waveform shape:', x.shape)\n",
    "\n",
    "postprocessed_batch = ProcessWithVGGish(vgg, x, sr)\n",
    "\n",
    "print(postprocessed_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Processing folder 132\n",
    "Processing folder 130\n",
    "Processing folder 029\n",
    "Processing folder 039\n",
    "Processing folder 155\n",
    "Processing folder 149\n",
    "Processing folder 057\n",
    "Processing folder 002\n",
    "Processing folder 083\n",
    "Processing folder 006\n",
    "Processing folder 126\n",
    "Processing folder 097\n",
    "Processing folder 125\n",
    "Processing folder 145\n",
    "Processing folder 076\n",
    "Processing folder 139\n",
    "Processing folder 142\n",
    "Processing folder 037\n",
    "Processing folder 104\n",
    "Processing folder 059\n",
    "Processing folder 140\n",
    "Processing folder 080\n",
    "Processing folder 010\n",
    "Processing folder 075\n",
    "Processing folder 115\n",
    "Processing folder 043\n",
    "Processing folder 033\n",
    "Processing folder 063\n",
    "Processing folder 124\n",
    "Processing folder 018\n",
    "Processing folder 131\n",
    "Processing folder 091\n",
    "Processing folder 047\n",
    "Processing folder 154\n",
    "Processing folder 100\n",
    "Processing folder 118\n",
    "Processing folder 056\n",
    "Processing folder 086\n",
    "Processing folder 088\n",
    "Processing folder 081\n",
    "Processing folder 078\n",
    "Processing folder 090\n",
    "Processing folder 027\n",
    "Processing folder 045\n",
    "Processing folder 141\n",
    "Processing folder 098\n",
    "Processing folder 012\n",
    "Processing folder 137\n",
    "Processing folder 138\n",
    "Processing folder 079\n",
    "Processing folder 068\n",
    "Processing folder 143\n",
    "Processing folder 123\n",
    "Processing folder 049\n",
    "Processing folder 129\n",
    "Processing folder 085\n",
    "Processing folder 112\n",
    "Processing folder 135\n",
    "Processing folder 120\n",
    "Processing folder 055\n",
    "Processing folder 014\n",
    "Processing folder 030\n",
    "Processing folder 071\n",
    "Processing folder 041\n",
    "Processing folder 133\n",
    "Processing folder 152\n",
    "Processing folder 044\n",
    "Processing folder 051\n",
    "Processing folder 114\n",
    "Processing folder 035\n",
    "Processing folder 005\n",
    "Processing folder 153\n",
    "Processing folder 064\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
